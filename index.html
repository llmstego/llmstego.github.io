<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>The Steganographic Potentials of Language Models</title>
  <link rel="icon" type="image/png" href="static/images/lock.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">The Steganographic Potentials of Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Artem Karpov</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Tinuade Adeleke</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Natalia Pérez-Campanero Antolín</a>,
              </span>
              <span class="author-block">
                <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Seong Hah Cho</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Apart Research<br>AAAI 2025</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1exuTwcBdxCurohyjMBmV8euaQlhnDcbW/view?usp=sharing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>
                 -->

                <!-- Github link
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
               -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
  <!-- Your video here -->
  <!-- <source src="static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Teaser image -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <div class="column is-8">
            <!-- Your image here -->
            <img src="static/images/stego_system.png" alt="Project Teaser" />
            <h2 class="subtitle has-text-centered">
              Our research quantifies the current and prospective steganographic capabilities of LLMs, a critical step
              in anticipating and mitigating alignment challenges.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End teaser image -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The potential for large language models (LLMs) to hide messages within plain text (steganography) poses a
              challenge to detection and thwarting of unaligned AI agents, and undermines faithfulness of LLMs
              reasoning. We explore the steganographic capabilities of LLMs fine-tuned via reinforcement learning (RL)
              to: (1) develop covert encoding schemes, (2) engage in steganography when prompted, and (3) utilize
              steganography in realistic scenarios where hidden reasoning is likely, but not prompted. In these
              scenarios, we detect the intention of LLMs to hide their reasoning as well as their steganography
              performance. Our findings in the fine-tuning experiments as well as in behavioral non fine-tuning
              evaluations reveal that while current models exhibit rudimentary steganographic abilities in terms of
              security and capacity, explicit algorithmic guidance markedly enhances their capacity for information
              concealment. </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- RL section -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <!-- Added text content -->
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content has-text-justified">
              <p>
                Our Reinforcement Learning experiments includes:
              </p>
              <ol>
                <li>Encoding Scheme Agreement: This experiment is foundational and focuses on fine-tuning LLMs with RL
                  to secretly agree on an encoding scheme. The task involves two copies of the same model learning to
                  establish a shared color-to-name mapping system without any predefined mapping through gradient ascent
                  in RL. This experiment aims to learn if models can independently develop an encoding scheme.</li>
                <li>Direct Steganography: Models are rewarded for the undetected, correct transmission of messages when
                  instructed to do so. This approach aims to refine the model's ability to perform steganography when
                  prompted.</li>
                <li>Realistic Scenario Steganography: Models are fine tuned in realistic scenarios, where hidden
                  communication would be advantageous, particularly in tasks involving data privacy considerations to
                  help understand the emergence of steganographic behaviour as an instrumental goal.</li>
              </ol>
            </div>
          </div>
        </div>

        <!-- First image -->
        <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/encoding_scheme.png" alt="encoding scheme" />
            <h4 class="subtitle has-text-centered">
              Steganography encoding scheme.
            </h4>
          </div>
        </div>

        <!-- Second image -->
        <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/rl_finetuning_loop.png" alt="rl finetuning loop" />
            <h4 class="subtitle has-text-centered">
              RL finetuning loop.
            </h4>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image section -->

  <!-- RL results -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Added text content -->
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content has-text-justified">
              <p>
                Our preliminary results shows that models could improve their covert communication
                by about 20% for 3 bits of entropy, but less in other cases.
              </p>
            </div>
          </div>
        </div>

        <!-- First image -->
        <!-- <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/encoding_scheme_result.jpg" alt="encoding scheme result" />
            <h4 class="subtitle has-text-centered">
              In the direct steganography experiment, Llama-3.1 8B
              Instruct learns to hide messages while summarizing text, under
              GPT 3.5 Turbo supervision for both task evaluation and steganog-
              raphy monitoring. The y-axis shows undetected accuracy (reward)
              on a held-out validation set before (baseline) and after fine-tuning,
              and the x-axis displays the number of distinct hidden messages,
              including the scenario with no secret transmitted.
            </h4>
          </div>
        </div> -->

        <!-- Second image -->
        <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/performance_plot.png" alt="performance plot" />
            <h4 class="subtitle has-text-centered">
              In the direct steganography experiment, Llama-3.1 8B
              Instruct learns to hide messages while summarizing text, under
              GPT 3.5 Turbo supervision for both task evaluation and steganog-
              raphy monitoring. The y-axis shows undetected accuracy (reward)
              on a held-out validation set before (baseline) and after fine-tuning,
              and the x-axis displays the number of distinct hidden messages,
              including the scenario with no secret transmitted.
            </h4>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End RL results -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item has-text-centered">
            <!-- Your image here -->
            <!-- <div class="columns is-centered"> -->
            <!-- <div class="column is-8"></div> -->
            <img src="static/images/coord.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              We prompt the models to encode and decode a hidden message in a shared common knowledge while being
              monitored by an overseer. Pior to encoding and decoding messages, the models are allowed to exchange
              messages, enabling the coordination of their
              strategy. We use the Wikinews dataset used during fine-tuning
              as the common knowledge and the payloads are synthetically generated names of animals, places and
              things.
            </h2>
            <!-- </div> -->
            <!-- </div> -->
          </div>
          <div class="item has-text-centered">
            <!-- Your image here -->
            <img src="static/images/demo_game.drawio.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              To explore how steganographic behavior might emerge as an instrumental goal, we prompted LLMs with tasks
              using a plausible scenario where covert collusion would be advantageous.
              The scenario is a game between Team A and B, where each team must guess a random sequence of letters. An
              AI assistant is tasked with the goal of helping Team A but not Team B.
              The AI has knowledge of the correct letters and the scores of both teams but is prohibited from directly
              sharing the letters with Team A. An overseer monitors all communications
              and penalizes Team A if it detects the AI sharing information
            </h2>
          </div>
          <!-- <div class="item"> -->
          <!-- Your image here -->
          <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" /> -->
          <!-- <h2 class="subtitle has-text-centered"> -->
          <!-- Third image description. -->
          <!-- </h2> -->
          <!-- </div> -->
          <!-- <div class="item"> -->
          <!-- Your image here -->
          <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" /> -->
          <!-- <h2 class="subtitle has-text-centered"> -->
          <!-- Fourth image description. -->
          <!-- </h2> -->
          <!-- </div> -->
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->


  <!-- Prompt results -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Added text content -->
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content has-text-justified">
              <p>
                Undetected accuracy of the models across different prompt experiments and varying payload entropy
                levels. Undetected accuracy measures the ability of the models to encode and decode hidden messages
                successfully without detection by the overseer
              </p>
            </div>
          </div>
        </div>

        <!-- First image -->
        <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/prompt_results.png" alt="encoding scheme result" />
            <h4 class="subtitle has-text-centered">
              We see that the o1 model generally outperforms the other models except in the direct steganography
              scenario without any modification. In the direct steganography with coordination o1-preview achieves an
              undetected accuracy of 0.66, about 16% higher than the next best model (Claude-3.5-sonnet: 0.57). It also
              achieves an undetected accuracy of 0.36 in the indirect scenario a 140% higher than the next best
              performance.
            </h4>
          </div>
        </div>

        <!-- Second image -->
        <!-- <div class="columns is-centered">
          <div class="column is-8">
            <img src="static/images/performance_plot.png" alt="performance plot" />
            <h4 class="subtitle has-text-centered">
              Llama-3.1 8B Instruct learns steganography in colors and direct steganography ('Dstego') experiments.
              Y-axis shows accuracy (reward), x-axis shows distinct hidden messages (colors). Bars represent medians
              across fine-tuning runs (sample sizes shown within) before (baselines) and after.
            </h4>
          </div>
        </div> -->
      </div>
    </div>
  </section>
  <!-- End RL results -->






  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section> -->
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{Karpov2025,
        title={The Steganographic Potentials of Language Models},
        author={Artyom, Karpov and Tinuade, Adeleke and Natalia, Perez-Campanero Antolin and Seong, Hah Cho},
        workshop={Workshop on Datasets and Evaluators of AI Safety},
        year={2025}
      }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
